{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cb6b9a9",
   "metadata": {},
   "source": [
    "# Vectorstores (with Chromadb) and Embeddings\n",
    "\n",
    "Recall the overall workflow for retrieval augmented generation (RAG)\n",
    "\n",
    "Edge cases:\n",
    "1. Duplicate data which cause duplicate chunks\n",
    "2. Semantic search is done on content, which ignores metadata info/scopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "561c4ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51c0751d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# Load PDF\n",
    "loaders = [\n",
    "    # Duplicate documents on purpose - messy data\n",
    "    PyPDFLoader(\"docs/cs229_lectures/MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(\"docs/cs229_lectures/MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(\"docs/cs229_lectures/MachineLearning-Lecture02.pdf\"),\n",
    "    PyPDFLoader(\"docs/cs229_lectures/MachineLearning-Lecture03.pdf\")\n",
    "]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af2916eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split docs into chunks\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79d2a2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbac1c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe2d458",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "\n",
    "Let's take our splits and embed them with OpenAI embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f67d925",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6a1620e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"i like dogs\"\n",
    "sentence2 = \"i like canines\"\n",
    "sentence3 = \"the weather is ugly outside\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d5bda05",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding1 = embedding.embed_query(sentence1)\n",
    "embedding2 = embedding.embed_query(sentence2)\n",
    "embedding3 = embedding.embed_query(sentence3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f170ab74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00de2e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96312275005236"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embedding1, embedding2) # higher is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdffce0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7703257495981691"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embedding1, embedding3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1440d15a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.759162740110803"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embedding2, embedding3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e0eb21",
   "metadata": {},
   "source": [
    "## Vectorstores - use Chromadb as it's lightweight and in-memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f272bdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82cbe209",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d26b3c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = 'docs/chroma/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d81219eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./docs/chroma  # remove old database files if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e84a1d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding, # use openai embedding\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8afa065c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac90eec",
   "metadata": {},
   "source": [
    "### Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24080c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"is there an email i can ask for help\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "722ec8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(question,k=3) # k = number of revelant docs to retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed8e4c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "222c7843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"cs229-qa@cs.stanford.edu. This goes to an acc ount that's read by all the TAs and me. So \\nrather than sending us email individually, if you send email to this account, it will \\nactually let us get back to you maximally quickly with answers to your questions.  \\nIf you're asking questions about homework probl ems, please say in the subject line which \\nassignment and which question the email refers to, since that will also help us to route \\nyour question to the appropriate TA or to me  appropriately and get the response back to \\nyou quickly.  \\nLet's see. Skipping ahead — let's see — for homework, one midterm, one open and term \\nproject. Notice on the honor code. So one thi ng that I think will help you to succeed and \\ndo well in this class and even help you to enjoy this cla ss more is if you form a study \\ngroup.  \\nSo start looking around where you' re sitting now or at the end of class today, mingle a \\nlittle bit and get to know your classmates. I strongly encourage you to form study groups \\nand sort of have a group of people to study with and have a group of your fellow students \\nto talk over these concepts with. You can also  post on the class news group if you want to \\nuse that to try to form a study group.  \\nBut some of the problems sets in this cla ss are reasonably difficult.  People that have \\ntaken the class before may tell you they were very difficult. And just I bet it would be \\nmore fun for you, and you'd probably have a be tter learning experience if you form a\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204d02ca",
   "metadata": {},
   "source": [
    "Persist the ChrombDB to disk so that we can use it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2747a24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168aef87",
   "metadata": {},
   "source": [
    "## Failure modes - duplicate data\n",
    "\n",
    "This seems great, and basic similarity search will get you 80% of the way there very easily. \n",
    "\n",
    "But there are some failure modes that can creep up. \n",
    "\n",
    "Here are some edge cases that can arise - we'll fix them in the next class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "79a9cf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about matlab?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "df2893d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(question,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a95dd5",
   "metadata": {},
   "source": [
    "Notice that we're getting duplicate chunks (because of the duplicate `MachineLearning-Lecture01.pdf` in the index).\n",
    "\n",
    "Semantic search fetches all similar documents, but does not enforce diversity.\n",
    "\n",
    "`docs[0]` and `docs[1]` are indentical because of duplicate data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e92ce72c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='those homeworks will be done in either MATLA B or in Octave, which is sort of — I \\nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn\\'t.  \\nSo I guess for those of you that haven\\'t s een MATLAB before, and I know most of you \\nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \\nplot data. And it\\'s sort of an extremely easy to  learn tool to use for implementing a lot of \\nlearning algorithms.  \\nAnd in case some of you want to work on your  own home computer or something if you \\ndon\\'t have a MATLAB license, for the purposes of  this class, there\\'s also — [inaudible] \\nwrite that down [inaudible] MATLAB — there\\' s also a software package called Octave \\nthat you can download for free off the Internet. And it has somewhat fewer features than MATLAB, but it\\'s free, and for the purposes of  this class, it will work for just about \\neverything.  \\nSo actually I, well, so yeah, just a side comment for those of you that haven\\'t seen \\nMATLAB before I guess, once a colleague of mine at a different university, not at \\nStanford, actually teaches another machine l earning course. He\\'s taught it for many years. \\nSo one day, he was in his office, and an old student of his from, lik e, ten years ago came \\ninto his office and he said, \"Oh, professo r, professor, thank you so much for your', metadata={'page': 8, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "89a71557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='those homeworks will be done in either MATLA B or in Octave, which is sort of — I \\nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn\\'t.  \\nSo I guess for those of you that haven\\'t s een MATLAB before, and I know most of you \\nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \\nplot data. And it\\'s sort of an extremely easy to  learn tool to use for implementing a lot of \\nlearning algorithms.  \\nAnd in case some of you want to work on your  own home computer or something if you \\ndon\\'t have a MATLAB license, for the purposes of  this class, there\\'s also — [inaudible] \\nwrite that down [inaudible] MATLAB — there\\' s also a software package called Octave \\nthat you can download for free off the Internet. And it has somewhat fewer features than MATLAB, but it\\'s free, and for the purposes of  this class, it will work for just about \\neverything.  \\nSo actually I, well, so yeah, just a side comment for those of you that haven\\'t seen \\nMATLAB before I guess, once a colleague of mine at a different university, not at \\nStanford, actually teaches another machine l earning course. He\\'s taught it for many years. \\nSo one day, he was in his office, and an old student of his from, lik e, ten years ago came \\ninto his office and he said, \"Oh, professo r, professor, thank you so much for your', metadata={'page': 8, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be453785",
   "metadata": {},
   "source": [
    "We can see a new failure mode.\n",
    "\n",
    "The question below asks a question about the third lecture, but includes results from other lectures as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d4c8e254",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about regression in the third lecture?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a445032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(question,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478a143f",
   "metadata": {},
   "source": [
    "Not all results are coming from Lecture 3, as the semantic search is done on the content of the docs only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4f677d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 0, 'source': 'docs/cs229_lectures/MachineLearning-Lecture03.pdf'}\n",
      "{'page': 0, 'source': 'docs/cs229_lectures/MachineLearning-Lecture03.pdf'}\n",
      "{'page': 2, 'source': 'docs/cs229_lectures/MachineLearning-Lecture02.pdf'}\n",
      "{'page': 2, 'source': 'docs/cs229_lectures/MachineLearning-Lecture02.pdf'}\n",
      "{'page': 14, 'source': 'docs/cs229_lectures/MachineLearning-Lecture03.pdf'}\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "382ad524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student: It’s the lowest it –  \n",
      "Instructor (Andrew Ng) :No, exactly. Right. So zero to the same, this is not the same, \n",
      "right? And the reason is, in logi stic regression this is diffe rent from before, right? The \n",
      "definition of this H subscript theta of XI is not the same as the definition I was using in \n",
      "the previous lecture. And in pa rticular this is no longer thet a transpose XI. This is not a \n",
      "linear function anymore. This is  a logistic function of theta transpose XI. Okay? So even \n",
      "though this looks cosmetically similar, even though this is similar on the surface, to the \n",
      "Bastrian descent rule I derive d last time for least squares regression this is actually a \n",
      "totally different learning algorithm. Okay? And it turns out that there’s actually no \n",
      "coincidence that you ended up with the same l earning rule. We’ll actually talk a bit more \n",
      "about this later when we talk about generalized linear models. But this is one of the most \n",
      "elegant generalized learning models that we’l l see later. That even though we’re using a \n",
      "different model, you actually ended up with wh at looks like the sa me learning algorithm \n",
      "and it’s actually no coincidence. Cool.  \n",
      "One last comment as part of a sort of l earning process, over here I said I take the \n",
      "derivatives and I ended up with this line . I didn’t want to make you sit through a long \n",
      "algebraic derivation, but later t oday or later this week, pleas e, do go home and look at our\n"
     ]
    }
   ],
   "source": [
    "print(docs[4].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f56a37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
